# 总结

## 一、机器学习

### 1. 机器学习概述

1）机器学习分类

- 有监督、无监督、半监督
- 批量学习、增量学习
- 基于实例的学习、基于模型的学习

2）机器学习的基本问题

- 回归问题：预测结果是连续的
- 分类问题：预测结果是离散的
- 聚类问题：无监督学习
- 强化学习问题：最优策略

3）机器学习的一般过程

收集数据 → 数据清洗 → 标注 → 选择模型 → 训练/评估 → 测试 → 应用及维护

### 2. 数据预处理

1）标准化：每列均值转换为0，标准差转换为1

2）范围缩放：最大值转换为1，最小值转换为0

3）归一化：将数值转换为百分比（按行）

4）二值化：将数值转换为0/1两个值

5）独热编码：将数值转换为一串0和一个1表示的格式

6）标签编码：将字符串转换为数值

### 3. 回归问题

#### 1）线性回归

- 线性模型：$y=w^Tx + b$
- 线性回归：根据样本分布（样本基本呈线性分布），找一个最优的线性模型，使用该模型执行预测
- 如何找到最优线性模型
  - 损失函数：度量模型预测值、真实值之间的差异
  
  - 梯度下降：沿损失函数梯度负方向调整参数
    $$
    w_i = w_i +\Delta w_i \\
    \Delta w_i = - \eta \frac{\partial E}{ \partial w_i}
    $$

- 线性回归的变种
  - Lasso回归：线性回归上添加L1正则项
  - 岭回归：线性回归上添加L2正则项

#### 2）多项式回归

- 多项式回归：最高此项超过1，用于样本呈非线性分布
- 多项式回归参数是线性的，可以理解成线性回归的扩展
- 欠拟合、过拟合
  - 欠拟合：拟合程度不够，表现为训练集、测试集下精度不高
  - 过拟合：模型过分拟合与训练样本，导致泛化能力不足，表现为训练集精度较高、测试集（新数据）精度较低
- 如何处理欠拟合、过拟合
  - 欠拟合：增加模型复杂度、增加特征
  - 过拟合：增加样本数量、降低模型复杂度、减少特征、正则化

#### 3）决策树回归

### 4. 分类问题

#### 1）逻辑回归

- 定义：二分类，先利用回归模型预测一个连续值，然后利用逻辑函数离散化处理
- 逻辑函数（sigmoid）：将负无穷到正无穷范围数字，转换到0~1之间
- 损失函数：交叉熵
- 二分类模型实现多分类：利用多个二分类模型

#### 2）决策树

- 定义：利用“同因同果”原理，利用树状结构对样本属性进行判断，将具有相同属性的样本放到同一个子节点下，根据叶子节点下的样本，用投票法实现分类，求平均值法实现回归
- 结构：根节点、决策节点、叶子节点（一批样本）
- 如何选择属性
  - 信息增益：划分前信息熵、划分后的信息熵的差值
  - 增益率：信息增益除以固有熵
  - 基尼系数
- 决策树枝剪：预枝剪、后枝剪
- 集成学习
  - 定义：利用多个模型学习，克服单个模型的局限
  - 强关联（Boosting，例如AdaBoosting）；弱关联（Bagging，例如随机森林）

#### 3）朴素贝叶斯

- 概率的术语：随机事件、概率、联合概率、条件概率、先验概率、后验概率

- 贝叶斯定理
  $$
  P(A|B) = \frac{P(A)P(B|A)}{P(B)}
  $$

- 朴素贝叶斯分类器：假设特征是独立的，利用贝叶斯定理计算术语每个类别的概率

#### 4）支持向量机

- 定义：二分类模型，在样本间寻找最优分割超平面（线性分类边界），使得支持向量离分类边界距离最远（间隔最大化）
- 线性可分、线性不可分
- 核函数：将线性不可分问题转换为高维度空间下的线性可分
  - 线性核函数
  - 多项式核函数
  - 径向基核函数

### 5. 聚类问题

1）定义：无监督学习，根据样本相似度，将样本划分到不同的群落（聚簇）

2）相似度度量方式：距离

- 欧式距离
- 曼哈顿距离
- 切比雪夫距离
- 闵式距离

3）聚类的划分

- 基于原型的聚类：k-means
- 基于密度的聚类：DBSCAN
- 基于层次的聚类：凝聚层次

4）聚类算法的比较

| 比较项           | K-Means  | DBSCAN   | 凝聚层次 |
| ---------------- | -------- | -------- | -------- |
| 类别             | 基于原型 | 基于密度 | 基于层次 |
| 有无聚类中心     | 有       | 无       | 无       |
| 提前设置K        | 需要     | 不需要   | 需要     |
| 噪声样本是否敏感 | 敏感     | 不敏感   | 不敏感   |



### 6. 模型评估与优化

1）分类问题性能度量

- 查准率：衡量误检
- 召回率（查全率）：衡量漏检
- F1：综合衡量查准率、召回率
- 混淆矩阵

2）训练集、测试集划分

3）交叉验证：将数据划分成K个折叠，每次以其中的一个折叠作为测试集，其它作为训练集，相当于获得了K份不同的数据，主要用于样本较少的情况

4）验证曲线、学习曲线

- 验证曲线：验证不同模型参数对模型的影响
- 学习曲线：验证不同规模训练集对模型的影响

5）超参数调优

- 网格搜索

- 随机搜索

  

## 二、深度学习

### 1. 感知机、神经网络

1）感知机：又称为神经元，接收多个输入，在线性函数计算下，产生输出（大于阈值输出1，小于阈值输出0）

2）感知机功能：处理线性可分问题（逻辑和、逻辑或）；构成神经网络

3）神经网络

- 结构：由很多神经元组成的、层状的结构，有向无环图，每个神经元和上一层、下一层每个节点连接，同一层神经元不相互连接
- 功能：通用近似定理证明，一个神经网络，只需要一个隐藏层，整个隐藏层包含足够多的神经元，在激活函数作用下，能够模拟出任意连续性函数

### 2. 激活函数

1）作用：将神经网络由线性扩展为非线性

2）常用激活函数

- 阶跃函数
- sigmoid
- tanh
- relu
- softmax

### 3. 损失函数、梯度下降

- 损失函数：度量预测值、真实值之间的差异
  - 均方差：回归问题
  - 交叉熵：分类问题
- 梯度下降
- 梯度下降方式
  - 随机梯度下降：每次随机抽取一个样本，根据预测值计算误差、梯度，执行梯度下降
  - 批量梯度下降：每次将所有样本输入模型，根据预测值计算误差、梯度
  - 小批量梯度下降：每次随机抽取一个批次样本，根据预测值计算误差、梯度
- 梯度消失与梯度爆炸
  - 梯度消失：梯度过小
  - 梯度爆炸：梯度过大，超过正常值范围

### 4. 反向传播算法

1）作用：求深度学习模型中，隐藏层的梯度

2）链式求导法则

### 5. 卷积神经网络

1）卷积：两个函数在某个维度上的叠加

2）卷积神经网络：在神经网络中加入卷积、池化操作的模型

- 卷积层：卷积运算，提取特征
- 池化层：降维
- 激活层：执行激活运算
- 全连接层：分类器
- 非标准层：dropout（缓解过拟合）、Batch normal

3）经典CNN：LeNet、AlexNet、VGG、GoogLeNet、ResNet



## 三、计算机视觉

### 1. 数字图像处理

1）基本概念：图像表示（单通道/多通道矩阵）、灰度级、色彩空间（RGB、HSV）、灰度化

2）色彩变换：灰度化、二值化、通道操作、灰度直方图、直方图均衡化

3）形态变换：仿射变换（旋转、平移、镜像）、缩放（最邻近差值、双线性差值）、裁剪、图像加减、透视变换、图像形态学（腐蚀、膨胀）

4）梯度相关：模板操作（锐化、模糊/降噪）、边沿提取、轮廓提取



### 2. 深度学习图像识别

#### 1）图像分类（基本问题）

#### 2）目标检测（基本问题）

- 定义：检测出图片中有什么物体（分类），对物体进行定位（回归）
- 两个系列
  - 两阶段检测：先产生候选区，再做分类、定位。特点：速度较慢、精度较高
  - 一阶段检测：没有产生候选区的过程，直接做分类、定位。特点：速度较快、精度相对较低
- 基本原理
  - 候选区域产生方式：滑动窗口、Selective Search、RPN（特征图上产生）
  - 数据表示：置信度、定位参数、分类参数
  - 效果评估：分类问题采用分类评估指标，定位问题采用IOU
  - NMS：多个预测结果中保留最好的
  - 多尺度检测与特征融合
- 两阶段检测：R-CNN, Fast R-CNN, Faster R-CNN
- 一阶段检测：YOLO系列

#### 3）OCR

- 定义：从图像中检测文字、识别文字的技术，包含文字检测、文字识别
- 评估指标：拒识率、误识率、识别速度、稳定性
- 文字检测模型
  - CTPN：适合检测水平文字
  - SegLink：适合检测带角度文字
- 文字识别模型：CRNN+CTC

#### 4）人脸检测与识别

- 人脸图像应用：人脸检测、人脸识别、人脸检索
- 单样本学习模型：孪生网络、三元神经网络

#### 5）图像分割（基本问题）

- 图像分割：本质是对每个像素进行分类
- 一般流程：原图 → 提取特征 → 上采样 → 预测出每个像素的类别
- 评估方式：像素精度、平均像素精度、平均交并比
- 经典模型：FCN、UNet、Mask R-CNN、DeepLab系列

## 四、关于项目的问题

1）如何构建数据集？

- 采集、收集数据
- 数据清洗
- 分门别类存放
- 标注

2）数据从哪里来？

- 历史交易中发生过的数据（价值最高）
- 自己采集、收集数据（项目最可能情况）
- 购买
- 爬虫（合法使用）
- 公共数据集（一般来说价值不高）

3）数据量究竟多大？

- 深度学习：起码达到百量级

4）数据量不够如何处理？

- 数据增强
- 选择能在少量数据集下工作的模型

5）采用的模型是什么？为什么？

- 根据实际问题，以及问题的难易程度，首选现有的、经典的、成熟的模型
- 如果不确定选择哪个模型，可以多个模型进行对比，择优使用
- 在有些情况下，可以多个模型配合使用，发挥各自的特长

6）什么情况下使用OpenCV，什么情况下使用深度学习？

- OpenCV：样本较少、情景单一、变化较小、干扰较少、不需要理解图像内容和场景
- 深度学习：样本数量充足、情景多变、干扰较多、环境复杂、需要理解图像的内容和场景

7）数据如何标注，谁来标注？

- 大公司：可能有专门标注人员，或者外包
- 中小企业：项目组成员完成
- 有些情况下，标注工作需要专业人员完成

8）为什么不选择XXX（例如VGG/AlexNet/ResNet）模型？

- 原则模型的依据：效果
- 最好回答出模型的特点

9）训练时使用CPU还是GPU？GPU从哪里来？型号？价格？

- 一般采用GPU
- GPU来源：工作机安装GPU；购买带GPU的云计算主机（按月/年、按实际使用小时计费）
- 查阅常用GPU的型号、价格、主要参数
- 其它：哪种型号的工业相机？分辨率？帧率？如何安装？

10）模型训练时间？

- 一定要估算
- 实际项目中，采用增量训练方式

11）准确率是多少？

- 一般要达到95%以上

12）模型如何部署、使用？

- 部署：服务器部署、客户端部署、嵌入式部署
- 使用方式：封装成网络服务、函数、类，供其它程序、人员、系统进行调用

13）项目周期多长？

- 小型项目：3~6个月
- 中型项目：6~12个月
- 大型项目：1~3年

14）项目组多少成员、如何分工？

- 成员数量根据项目规模确定
- 中小型企业项目，岗位分工不明确；大型企业或项目，分工明确些
- 例如：一个算法工程师，2~3个开发工程师

15）简历中项目应该描述的内容

- 项目需求：用在哪里？谁用？解决什么问题？
- 数据集：来源、数量、预处理手段
- 技术路线：模型、技术的选择（OCR、人脸首选第三方库）
- 调参优化过程
- 过拟合、欠拟合处理方式
- 效果

