{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "doc = \"Are you curious about tokenization? Let's see how it works! We need to analyze a couple of sentences with punctuations to see it in action.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 把样本按句子进行拆分  sent_list:句子列表\n",
    "sent_list = tk.sent_tokenize(doc)\n",
    "\n",
    "# 把样本按单词进行拆分  word_list:单词列表\n",
    "word_list = tk.word_tokenize(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['Are you curious about tokenization?',\n \"Let's see how it works!\",\n 'We need to analyze a couple of sentences with punctuations to see it in action.']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['Are',\n 'you',\n 'curious',\n 'about',\n 'tokenization',\n '?',\n 'Let',\n \"'s\",\n 'see',\n 'how',\n 'it',\n 'works',\n '!',\n 'We',\n 'need',\n 'to',\n 'analyze',\n 'a',\n 'couple',\n 'of',\n 'sentences',\n 'with',\n 'punctuations',\n 'to',\n 'see',\n 'it',\n 'in',\n 'action',\n '.']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['Are',\n 'you',\n 'curious',\n 'about',\n 'tokenization',\n '?',\n 'Let',\n \"'\",\n 's',\n 'see',\n 'how',\n 'it',\n 'works',\n '!',\n 'We',\n 'need',\n 'to',\n 'analyze',\n 'a',\n 'couple',\n 'of',\n 'sentences',\n 'with',\n 'punctuations',\n 'to',\n 'see',\n 'it',\n 'in',\n 'action',\n '.']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tk.WordPunctTokenizer()\n",
    "words = tokenizer.tokenize(doc)\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#词袋模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import nltk.tokenize as tk  #分词\n",
    "import sklearn.feature_extraction.text as ft  #文本特征提取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "doc = \"Are you curious about tokenization? Let's see how it works! We need to analyze a couple of sentences with punctuations to see it in action.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sents = tk.sent_tokenize(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cv = ft.CountVectorizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "res = cv.fit_transform(sents).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0]\n",
      " [0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 2 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limuyuan/Documents/Artificial-Intelligence-Note/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['about',\n 'action',\n 'analyze',\n 'are',\n 'couple',\n 'curious',\n 'how',\n 'in',\n 'it',\n 'let',\n 'need',\n 'of',\n 'punctuations',\n 'see',\n 'sentences',\n 'to',\n 'tokenization',\n 'we',\n 'with',\n 'works',\n 'you']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#词频，对词袋模型进行归一化\n",
    "import sklearn.preprocessing as sp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.2       , 0.        , 0.        , 0.2       , 0.        ,\n        0.2       , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.2       , 0.        , 0.        , 0.        ,\n        0.2       ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.2       , 0.        , 0.2       , 0.2       ,\n        0.        , 0.        , 0.        , 0.2       , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.2       ,\n        0.        ],\n       [0.        , 0.07142857, 0.07142857, 0.        , 0.07142857,\n        0.        , 0.        , 0.07142857, 0.07142857, 0.        ,\n        0.07142857, 0.07142857, 0.07142857, 0.07142857, 0.07142857,\n        0.14285714, 0.        , 0.07142857, 0.07142857, 0.        ,\n        0.        ]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.normalize(res, norm='l1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#TF-IDF\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#\n",
    "cv = ft.CountVectorizer()\n",
    "bow = cv.fit_transform(sents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "tt = ft.TfidfTransformer()\n",
    "res = tt.fit_transform(bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136  0.         0.         0.4472136  0.         0.4472136\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4472136  0.\n",
      "  0.         0.         0.4472136 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.49047908 0.         0.37302199 0.49047908 0.         0.\n",
      "  0.         0.37302199 0.         0.         0.         0.\n",
      "  0.         0.49047908 0.        ]\n",
      " [0.         0.25685987 0.25685987 0.         0.25685987 0.\n",
      "  0.         0.25685987 0.19534855 0.         0.25685987 0.25685987\n",
      "  0.25685987 0.19534855 0.25685987 0.51371974 0.         0.25685987\n",
      "  0.25685987 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(res.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limuyuan/Documents/Artificial-Intelligence-Note/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['about',\n 'action',\n 'analyze',\n 'are',\n 'couple',\n 'curious',\n 'how',\n 'in',\n 'it',\n 'let',\n 'need',\n 'of',\n 'punctuations',\n 'see',\n 'sentences',\n 'to',\n 'tokenization',\n 'we',\n 'with',\n 'works',\n 'you']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}