{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from gensim import corpora, models\n",
    "from jieba import analyse\n",
    "import functools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 停用词表加载方法\n",
    "def get_stopword_list():\n",
    "    # 停用词表存储路径，每一行为一个词，按行读取进行加载\n",
    "    # 进行编码转换确保匹配准确率\n",
    "    stop_word_path = 'stopword.txt'\n",
    "    with open(stop_word_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    stopword_list = [sw.replace('\\n', '') for sw in lines]\n",
    "    return stopword_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "stopword_list = get_stopword_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 去除停用词\n",
    "def word_filter(seg_list):  #传入分词后的列表\n",
    "    filter_list = []\n",
    "    for word in seg_list:\n",
    "        # 过滤停用词表中的词，以及长度为<2的词\n",
    "        if not word in stopword_list and len(word) > 1:\n",
    "            filter_list.append(word)\n",
    "\n",
    "    return filter_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 数据加载，pos为是否词性标注的参数，corpus_path为数据集路径\n",
    "def load_data(corpus_path):\n",
    "    # 调用上面方式对数据集进行处理，处理后的每条数据仅保留非干扰词\n",
    "    doc_list = []\n",
    "    for line in open(corpus_path, 'r', encoding='utf-8'):  # 循环读取一行(一行即一个文档)\n",
    "        content = line.strip()  # 去空格\n",
    "        seg_list = jieba.cut(content)  # 分词\n",
    "        filter_list = word_filter(seg_list)  # 去除停用词\n",
    "        doc_list.append(filter_list)  # 将分词后的内容添加到列表\n",
    "\n",
    "    return doc_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# idf值统计方法\n",
    "def train_idf(doc_list):\n",
    "    idf_dic = {}\n",
    "    tt_count = len(doc_list)  # 总文档数\n",
    "\n",
    "    # 每个词出现的文档数\n",
    "    for doc in doc_list:\n",
    "        doc_set = set(doc)  # 将词推入集合去重\n",
    "        for word in doc_set:  # 词语在文档中\n",
    "            idf_dic[word] = idf_dic.get(word, 0.0) + 1.0  # 文档数加1\n",
    "\n",
    "    # 按公式转换为idf值，分母加1进行平滑处理\n",
    "    for word, doc_cnt in idf_dic.items():\n",
    "        idf_dic[word] = math.log(tt_count / (1.0 + doc_cnt))\n",
    "\n",
    "    # 对于没有在字典中的词，默认其仅在一个文档出现，得到默认idf值\n",
    "    default_idf = math.log(tt_count / (1.0))\n",
    "\n",
    "    return idf_dic, default_idf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# TF-IDF类\n",
    "class TfIdf(object):\n",
    "    def __init__(self, idf_dic, default_idf, word_list, keyword_num):\n",
    "        \"\"\"\n",
    "        TfIdf类构造方法\n",
    "        :param idf_dic: 训练好的idf字典\n",
    "        :param default_idf: 默认idf值\n",
    "        :param word_list: 待提取文本\n",
    "        :param keyword_num: 关键词数量\n",
    "        \"\"\"\n",
    "        self.word_list = word_list\n",
    "        self.idf_dic, self.default_idf = idf_dic, default_idf  # 逆文档频率\n",
    "        self.tf_dic = self.get_tf_dic()  # 词频\n",
    "        self.keyword_num = keyword_num\n",
    "\n",
    "    # 统计tf值\n",
    "    def get_tf_dic(self):\n",
    "        tf_dic = {}  # 词频字典\n",
    "        for word in self.word_list:\n",
    "            tf_dic[word] = tf_dic.get(word, 0.0) + 1.0\n",
    "\n",
    "        total = len(self.word_list)  # 词语总数\n",
    "        for word, word_cnt in tf_dic.items():\n",
    "            tf_dic[word] = float(word_cnt) / total\n",
    "\n",
    "        return tf_dic\n",
    "\n",
    "    # 按公式计算tf-idf\n",
    "    def get_tfidf(self):\n",
    "        tfidf_dic = {}\n",
    "        for word in self.word_list:\n",
    "            idf = self.idf_dic.get(word, self.default_idf)\n",
    "            tf = self.tf_dic.get(word, 0)\n",
    "\n",
    "            tfidf = tf * idf  # 计算TF-IDF\n",
    "            tfidf_dic[word] = tfidf\n",
    "\n",
    "        # 根据tf-idf排序，去排名前keyword_num的词作为关键词\n",
    "        s_list = sorted(tfidf_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "        # print(s_list)\n",
    "        top_list = s_list[:self.keyword_num]  # 切出前N个\n",
    "        for k, v in top_list:\n",
    "            print(k + \", \", end='')\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def tfidf_extract(word_list, keyword_num=20):\n",
    "    doc_list = load_data('corpus.txt')  # 读取文件内容\n",
    "    # print(doc_list)\n",
    "    idf_dic, default_idf = train_idf(doc_list) # 计算逆文档频率\n",
    "\n",
    "    tfidf_model = TfIdf(idf_dic, default_idf, word_list, keyword_num)\n",
    "    tfidf_model.get_tfidf()\n",
    "\n",
    "\n",
    "def textrank_extract(text, keyword_num=20):\n",
    "    keywords = analyse.textrank(text, keyword_num)\n",
    "    # 输出抽取出的关键词\n",
    "    for keyword in keywords:\n",
    "        print(keyword + \", \", end='')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF模型结果：\n",
      "历史, 中国共产党, 百年, 历史性, 华诞, 一百年, 奋斗目标, 交汇, 节点, 十九, 六中全会, 全会, 奋斗, 重大成就, 着重, 阐释, 十八, 党和国家, 成就, 变革, \n",
      "TextRank模型结果：\n",
      "历史, 历史性, 意义, 成就, 决议, 审议, 发生, 系统, 总结, 全面, 节点, 关键, 交汇, 召开, 具有, 全会, 取得, 事业, 自信, 变革, \n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"在中国共产党百年华诞的重要时刻，在“两个一百年”奋斗目标历史交汇关键节点，\n",
    "    党的十九届六中全会的召开具有重大历史意义。全会审议通过的《决议》全面系统总结了党的百年奋斗\n",
    "    重大成就和历史经验，特别是着重阐释了党的十八大以来党和国家事业取得的历史性成就、发生的历史性变革，\n",
    "    充分彰显了中国共产党的历史自觉与历史自信。\"\"\"\n",
    "\n",
    "#stopword_list = get_stopword_list()\n",
    "\n",
    "seg_list = jieba.cut(text)  # 分词\n",
    "filter_list = word_filter(seg_list)\n",
    "\n",
    "# TF-IDF提取关键词\n",
    "print('TF-IDF模型结果：')\n",
    "tfidf_extract(filter_list)\n",
    "\n",
    "# TextRank提取关键词\n",
    "print('TextRank模型结果：')\n",
    "textrank_extract(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}