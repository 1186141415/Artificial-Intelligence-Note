{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 6. 综合案例\n",
    "\n",
    "#### 1）垃圾邮件分类\n",
    "\n",
    "- 数据集介绍：包含5000份正常邮件、5001份垃圾邮件的样本\n",
    "- 文本特征处理方式：采用TF-IDF作为文本特征值\n",
    "- 模型选择：朴素贝叶斯、支持向量机模型\n",
    "- 基本流程：读取数据 → 去除停用词和特殊符号 → 计算TF-IDF特征值 → 模型训练 → 预测 → 打印结果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 利用TF-IDF特征、朴素贝叶斯/支持向量机实现垃圾邮件分类\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_name_map = [\"垃圾邮件\", \"正常邮件\"]\n",
    "\n",
    "\n",
    "# 分词\n",
    "def tokenize_text(text):\n",
    "    tokens = jieba.cut(text)  # 分词\n",
    "    tokens = [token.strip() for token in tokens]  # 去空格\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    # escape函数对字符进行转义处理\n",
    "    # compile函数用于编译正则表达式，生成一个 Pattern 对象\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    # filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表\n",
    "    # sub函数进行正则匹配字符串替换\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# 去除停用词\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)  # 分词、去空格\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]  # 去除停用词\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# 规范化处理\n",
    "def normalize_corpus(corpus):\n",
    "    result = []  # 处理结果\n",
    "\n",
    "    for text in corpus:  # 遍历每个词汇\n",
    "        text = remove_special_characters(text)  # 去除标点符号\n",
    "        text = remove_stopwords(text)  # 去除停用词\n",
    "        result.append(text)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def tfidf_extractor(corpus):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    '''\n",
    "    获取数据\n",
    "    :return: 文本数据，对应的labels\n",
    "    '''\n",
    "    corpus = []  # 邮件内容\n",
    "    labels = []  # 标签(0-垃圾邮件 1-正常邮件)\n",
    "\n",
    "    # 正常邮件\n",
    "    with open(\"ham_data.txt\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            corpus.append(line)\n",
    "            labels.append(1)\n",
    "\n",
    "    # 垃圾邮件\n",
    "    with open(\"spam_data.txt\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            corpus.append(line)\n",
    "            labels.append(0)\n",
    "\n",
    "    return corpus, labels\n",
    "\n",
    "\n",
    "# 过滤空文档\n",
    "def remove_empty_docs(corpus, labels):\n",
    "    filtered_corpus = []\n",
    "    filtered_labels = []\n",
    "\n",
    "    for doc, label in zip(corpus, labels):\n",
    "        if doc.strip():\n",
    "            filtered_corpus.append(doc)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    return filtered_corpus, filtered_labels\n",
    "\n",
    "\n",
    "# 计算并打印分类指标\n",
    "def print_metrics(true_labels, predicted_labels):\n",
    "    # Accuracy\n",
    "    accuracy = metrics.accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Precision\n",
    "    precision = metrics.precision_score(true_labels,\n",
    "                                        predicted_labels,\n",
    "                                        average='weighted')\n",
    "\n",
    "    # Recall\n",
    "    recall = metrics.recall_score(true_labels,\n",
    "                                  predicted_labels,\n",
    "                                  average='weighted')\n",
    "\n",
    "    # F1\n",
    "    f1 = metrics.f1_score(true_labels,\n",
    "                          predicted_labels,\n",
    "                          average='weighted')\n",
    "\n",
    "    print(\"正确率: %.2f, 查准率: %.2f, 召回率: %.2f, F1: %.2f\" % (accuracy, precision, recall, f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/xw/r4jf50z15dv7m1bfg3f55mcw0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总的数据量: 10001\n",
      "label: 1  邮件内容: 讲的是孔子后人的故事。一个老领导回到家乡，跟儿子感情不和，跟贪财的孙子孔为本和睦。 老领导的弟弟魏宗万是赶马车的。 有个洋妞大概是考察民俗的，在他们家过年。 孔为本总想出国，被爷爷教育了。 最后，一家人基本和解。 顺便问另一类电影，北京青年电影制片厂的。中越战背景。一军人被介绍了一个对象，去相亲。女方是军队医院的护士，犹豫不决，总是在回忆战场上负伤的男友，好像还没死。最后 男方表示理解，归队了。\n",
      "\n",
      "label: 1  邮件内容: 不至于吧，离开这个破公司就没有课题可以做了？ 谢谢大家的关心，她昨天晚上睡的很好。MM她自己已经想好了。见机行事吧，拿到相关的能出来做论文的材料，就马上辞职。 唉！看看吧，说不定还要各为XDJM帮出出找工作的主意呢。MM学通信的，哈尔滨工程大学的研究生，不想在哈碌碌无为的做设计，因此才出来的。先谢谢了啊。！！！ 本人语文不好，没加标点。辛苦那些看不懂的XDJM么了。\n",
      "\n",
      "label: 1  邮件内容: 生一个玩玩，不好玩了就送人 第一，你要知道，你们恋爱前，你爹妈对她是毫无意义的。没道理你爹妈就要求她生孩子，她就得听话。换句话说，你岳父母要未来孩子跟妈姓，你做的到吗？夫妻是平等的。如果你没办法答应岳父母，她干吗答应你爹妈呢？ 第二，有了孩子你养不养的起？不是说想生就生，图你爹妈一个高兴，如果没有房子，没有充足的财力，生孩子只会带给你们更多的困难，生小孩容易，养小孩难啊。\n",
      "\n",
      "label: 1  邮件内容: 微软中国研发啥？本地化？ 新浪科技讯 8月24日晚10点，微软中国对外宣布说，在2006财年(2005年7月-2006年6月)，公司将在中国招聘约800名新员工。 其中，一半以上的新聘人员将为研发人员，其他将是销售、市场和服务人员。同时，有近300个职位将面向新毕业的大学本科生、硕士研究生、MBA和博士生。 在2005财年，微软在中国的业务取得了骄人成绩，成为微软全球增长速度最快的子公司之一。\n",
      "\n",
      "label: 1  邮件内容: 要是他老怕跟你说话耽误时间 你可得赶紧纠正他这个观点 标  题: Re: 今天晚上的事情，有点郁闷 这个...其实以前有问题的时候都是当面解决，后来他说你有什么想不通的可以到板上去 问问别人，然后你就知道是谁不对了，所以这次我就来问，我觉得挺好，避免正面冲突， 他最怕耽误他时间，这样正好也不耽误他时间，也解了我的心结 : 感觉这两人都不够坦诚 : gg郁闷了就找mm别扭 : mm别扭了就到版上哭诉 -- 淡泊以明志，宁静以至远\n",
      "\n",
      "label: 1  邮件内容: 有病！ 亲爱的全体清华MM: 你们好!我的个人情况,相信你们都已经熟悉了.如果有不熟悉的,可以在水木未明上找朋友们了解.总之,我的条件是不错的.应该属于又帅又有钱的那种类型吧. 久闻天下美女数北京，北京美女在清华。说实话，你们和我身边的那些北大mm是完全没有可比性的,说句不好听的,我身边的mm,除了是个女的,就什么也不是了.我生活在这样的环境里,是一种悲剧.希望众清华mm同情理解.\n",
      "\n",
      "label: 1  邮件内容: 你以前是不是来发过贴子 我和我老婆是异地恋，差不多是第一代网恋吧，有5年多的历史了。去年年底登记结婚，最近发生的很多事情，突然让我觉得我们的婚姻和感情会不可靠。 我是一个乙肝病毒携带者，俗称小三阳。身体状态良好。本来没有什么，她打过乙肝疫苗，有抗体。什么情况都不会发生。 但是她妈妈无法接受，一次次吓唬她，一次次用极其极端的话来威胁她。\n",
      "\n",
      "label: 1  邮件内容: 是生的啊...... 晕倒 标  题: Re: show一下今晚做的剁椒土豆泥 不好意思，我不是说土豆是蒸的，我是说葱花。 应该放生的，最多开水烫一下（烫葱花的操作没听说过吧？我发明的） : 我确实是蒸的土豆不是煮的,怎么看出来的啊...... : 后来是用锅下油炒的 -- 高尚的人追求事业与爱情 平庸的人渴望金钱与美女 卑鄙的人则充满铜臭和情欲 问题是：有区别吗？\n",
      "\n",
      "label: 1  邮件内容: 记忆中教父笑过这么几次： 一次是女儿婚礼照相时， 一次是见到他的义子-那个歌手时， 一次是看到麦克在医院守护自己时， 一次是在和麦克的儿子，就是自己的孙子嬉戏时，就在这最开心的时刻死去 《教父》是十多年前在学校的录像厅看得，此后一直想再看一遍，可是一直没有看。忘得差不多了： 教父的那张从来不笑的脸。感觉他的下巴略微外突。 那个电影制片早上醒来看到他床上放着的马头。感觉教父解决问题真干脆利落\n",
      "\n",
      "label: 1  邮件内容: 我公司为北京一高新技术企业，主要从事石油、石化设备、工艺技术研发，现想招一名化工工艺或化学工程、石油加工等专业工程师一名，待遇优厚。要求最好有两年以上石化炼厂工作经验，熟悉工艺计算和化工装置调试等，本科以上学历，有意者请发简历至：litz@newbaron.com或leetzee@vip.sina.com,勿回站内，电话：13321199559多谢，公司网址：www.newbaron.com 现在学工艺的真难找吗，不应该啊\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.009 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于tfidf的贝叶斯模型\n",
      "正确率: 1.00, 查准率: 1.00, 召回率: 1.00, F1: 1.00\n",
      "\n",
      "基于tfidf的支持向量机模型\n",
      "正确率: 1.00, 查准率: 1.00, 召回率: 1.00, F1: 1.00\n",
      "\n",
      "真实类别: 正常邮件  预测结果: 正常邮件\n",
      "邮件内容【 发信人: iliuzhongqi (我爱清华，更爱我的小猪), 信区: SEM.THU 标  题: 咨询一个相关分析的问题 我看到某权威期刊上的一篇论文， 做1952到2002年中国 “GDP――人口死亡率”之间的相关性验证 对数据没有作任何处理 用的是pearson相关系数 GDP和人口死亡率都不是正态分布的数据 能用pearson相关系数来验证吗？ 似乎应该用等级相关分析呀？ 】\n",
      "\n",
      "真实类别: 垃圾邮件  预测结果: 垃圾邮件\n",
      "邮件内容【 尊敬的客户您好: 中国东方航空公司上海售票处销售国内外特价机票,3-8折, 可随时来电来邮咨询,上海市内24小时免费送票 地址:上海市闸北区天目东路206号山水航空服务有限公司 电话:021-51270965 51270967 51270969 传真:51270969 QQ:76482909             MSN:majunxang8888@msn.com E-mail  majunxiang8888@126.com 】\n",
      "\n",
      "真实类别: 正常邮件  预测结果: 正常邮件\n",
      "邮件内容【 sigh，又来ile 当你谈恋爱的时候，你会觉得无比的甜蜜和幸福。因为能够到城里来念大学、和你相识的男孩子，都是从农村跳龙门走出来的优秀分子，他们坚定、上进、能吃苦、有一定的阅历，和他们在一起总是会对生活充满憧憬。 但这一切只能局限在纯粹的感情层面上，当你们要从恋爱进入“结婚”，走进现实生活的时候，就会发现原来感情在现实的力量面前远没有你所想象的那么强大。 第一眼见到他，你可能已经被他迷住了。 】\n",
      "\n",
      "真实类别: 正常邮件  预测结果: 正常邮件\n",
      "邮件内容【 其实怕的是一大群穷亲戚要你们小俩口资助以及农村父母的医疗问题,这又不是 风花雪月其乐融融的事,生病了你治还是不治,到那时候小孩要上学要供房子要 生活要支付大笔大笔的医疗费,压得你能喘得过气来吗?没这心理准备最好别想 的太美好 我是城市的姑娘，真搞不董为什么大家这么在乎农村的gg？ 有什么麻烦的？本来就该孝敬爹娘，不管是谁的爹娘 我很喜欢三代同堂其乐融融的热闹劲儿 】\n",
      "\n",
      "真实类别: 垃圾邮件  预测结果: 垃圾邮件\n",
      "邮件内容【 手机一卡多号，媲美世界风双模手机！ WWW.81CDMA.COM 】\n",
      "\n",
      "真实类别: 正常邮件  预测结果: 正常邮件\n",
      "邮件内容【 我的要求貌似是喝酒随便喝醉了不许jjww,抽烟随便姿势要好看,玩游戏随便最好能让我旁观.上网随便最好还能给我下在电视剧,聊天随便爱跟谁聊都行,不过原则是不许上水木,找小姐随便注意安全,赌博也随便有本事封堵比赢的话我就跟着他去澳门如果不能缝赌必赢那别总输也凑合了.. 纵观我们的差别..我总算知道为什么你是3%我市那个人什么什么夫.... 看来我对男人的要求还是高的 不抽烟不喝酒不玩儿游戏不上网聊天不找小姐不赌博 】\n",
      "\n",
      "真实类别: 垃圾邮件  预测结果: 垃圾邮件\n",
      "邮件内容【 广州凯旋贸易有限公司， 有普通商品销售发票， 服务发票代开！ 联系人：周先生 联系电话：020-35611959 13824491272 E-mail:lyhabc88@hotmailc.om 】\n",
      "\n",
      "真实类别: 垃圾邮件  预测结果: 垃圾邮件\n",
      "邮件内容【 精彩就再这里，快快进来~！你会被她诱惑吗、还等什么呢，来吧~！ k酷爱 酷爱 酷爱 酷爱 】\n",
      "\n",
      "真实类别: 垃圾邮件  预测结果: 垃圾邮件\n",
      "邮件内容【 中信（国际）电子科技有限公司推出新产品： 升职步步高、做生意发大财、连找情人都用的上，详情进入 网  址:  http://www.usa6688.com/ccc 电话：020-33770208   服务热线：013650852999 】\n",
      "\n",
      "真实类别: 正常邮件  预测结果: 正常邮件\n",
      "邮件内容【 周一上午第2节或周5上午第二节均可，我试过了，虽然选课说明限男生，不过女生还是可以选到课的。 刚巧又多出了几个名额，所以想征爱好篮球的MM同去。两个人也比较好作分组练习。 据说老师看上去比较仁慈，所以我们选了课再去找老师说说应该没问题吧。 不知道还有没有MM想去？如果没人，那我一个人也不好意思去了，55~~~~ 另外，就在刚刚发完这段话时发现周五的只剩一个名额了，所以只能同选周一的了~~~不知道有没有mm愿意？ 】\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    global stopword_list\n",
    "\n",
    "    # 读取停用词\n",
    "    with open(\"stop_words.utf8\", encoding=\"utf8\") as f:\n",
    "        stopword_list = f.readlines()\n",
    "\n",
    "    corpus, labels = get_data()  # 加载数据\n",
    "    corpus, labels = remove_empty_docs(corpus, labels)\n",
    "    print(\"总的数据量:\", len(labels))\n",
    "\n",
    "    # 打印前N个样本\n",
    "    for i in range(10):\n",
    "        print(\"label:\", labels[i], \" 邮件内容:\", corpus[i])\n",
    "\n",
    "    # 对数据进行划分\n",
    "    train_corpus, test_corpus, train_labels, test_labels = ms.train_test_split(corpus,\n",
    "                                                                               labels,\n",
    "                                                                               test_size=0.10,\n",
    "                                                                               random_state=36)\n",
    "\n",
    "    # 规范化处理\n",
    "    norm_train_corpus = normalize_corpus(train_corpus)\n",
    "    norm_test_corpus = normalize_corpus(test_corpus)\n",
    "\n",
    "    # tfidf 特征\n",
    "    ## 先计算tf-idf\n",
    "    tfidf_vectorizer, tfidf_train_features = tfidf_extractor(norm_train_corpus)\n",
    "    ## 再用刚刚训练的tf-idf模型计算测试集tf-idf\n",
    "    tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)\n",
    "    # print(tfidf_test_features)\n",
    "    # print(tfidf_test_features)\n",
    "\n",
    "    # 基于tfidf的多项式朴素贝叶斯模型\n",
    "    print(\"基于tfidf的贝叶斯模型\")\n",
    "    nb_model = MultinomialNB()  # 多分类朴素贝叶斯模型\n",
    "    nb_model.fit(tfidf_train_features, train_labels)  # 训练\n",
    "    mnb_pred = nb_model.predict(tfidf_test_features)  # 预测\n",
    "    print_metrics(true_labels=test_labels, predicted_labels=mnb_pred)  # 打印测试集下的分类指标\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # 基于tfidf的支持向量机模型\n",
    "    print(\"基于tfidf的支持向量机模型\")\n",
    "    svm_model = SGDClassifier()  #分类器模块，没有指定会默认使用SVM\n",
    "    svm_model.fit(tfidf_train_features, train_labels)  # 训练\n",
    "    svm_pred = svm_model.predict(tfidf_test_features)  # 预测\n",
    "    print_metrics(true_labels=test_labels, predicted_labels=svm_pred)  # 打印测试集下的分类指标\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # 打印测试结果\n",
    "    num = 0\n",
    "    for text, label, pred_lbl in zip(test_corpus, test_labels, svm_pred):\n",
    "        print('真实类别:', label_name_map[int(label)], ' 预测结果:', label_name_map[int(pred_lbl)])\n",
    "        print('邮件内容【', text.replace(\"\\n\", \"\"), '】')\n",
    "        print(\"\")\n",
    "\n",
    "        num += 1\n",
    "        if num == 10:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train_features.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}