{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "import ssl  #下载数据忽略证书"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class FashionMnist:\n",
    "    out_feature1 = 12  #第一组卷机核数量\n",
    "    out_feature2 = 24  #第二组卷机核数量\n",
    "    con_neuroons = 512  #第一个全联接神经元数量\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.data = read_data_sets(path, one_hot=True)\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def init_weight_var(self, shape):\n",
    "        '''根据指定形状初始化权重'''\n",
    "\n",
    "        #截尾正态分布\n",
    "        init_val = tf.truncated_normal(shape=shape,\n",
    "                                       stddev=0.1)  #标准差\n",
    "        return tf.Variable(init_val)\n",
    "\n",
    "    def init_bias_var(self, shape):\n",
    "        '''根据指定形状初始化偏置'''\n",
    "\n",
    "        #截尾正态分布\n",
    "        init_val = tf.constant(1.0, shape=shape)\n",
    "        return tf.Variable(init_val)\n",
    "\n",
    "    def conv2d(self, x, w):\n",
    "        '''\n",
    "        二维卷机\n",
    "        :param x: 输入数据\n",
    "        :param w: 卷机核\n",
    "        :return: 卷机结果\n",
    "        '''\n",
    "\n",
    "        return tf.nn.conv2d(input=x,\n",
    "                            filters=w,  #滤波器\n",
    "                            strides=[1, 1, 1, 1],  #每个纬度上要有卷机，原始数据是4纬度的,翻译过来是每一张图，横向1，纵向1，1通道步幅度\n",
    "                            padding='SAME')  #SAME可以做同纬卷机\n",
    "\n",
    "    def max_pool_2x2(self, x):\n",
    "        '''\n",
    "        2x2区域最大池化\n",
    "        :param x: 卷机结果\n",
    "        :return: 池化结果\n",
    "        '''\n",
    "\n",
    "        return tf.nn.max_pool(value=x,  #输入数据\n",
    "                              ksize=[1, 2, 2, 1],  #池化区域，每1张图 2x2区域 1通道\n",
    "                              strides=[1, 2, 2, 1],  #池化步长\n",
    "                              padding='SAME')  #步长超过原图，自适应补0\n",
    "\n",
    "    def creat_conv_pool_layer(self, input, input_feature, out_feature):\n",
    "        '''\n",
    "        卷机池化组\n",
    "        :param input: 输入数据\n",
    "        :param input_feature: 输入特征数量\n",
    "        :param out_feature: 输出特征数量\n",
    "        :return: 返回计算结果\n",
    "        '''\n",
    "        filter_w = self.init_weight_var(\n",
    "            shape=[5, 5, input_feature,\n",
    "                   out_feature])  #一次只能处理一张图片，input_feature是1，因为是1通道的灰度图，翻译过来就是5x5的卷机，从input_feature个通道转化为out_feature通道，因为每次都只能处理一个图，所以表示第几张图的纬度不写\n",
    "        b_conv = self.init_bias_var(shape=[out_feature])\n",
    "\n",
    "        h_conv = tf.nn.relu(self.conv2d(x=input, w=filter_w) + b_conv)\n",
    "\n",
    "        h_pool = self.max_pool_2x2(h_conv)\n",
    "\n",
    "        return h_pool\n",
    "\n",
    "    def creat_fc_layer(self, h_pool_flat, input_freature, con_neurons):\n",
    "        '''\n",
    "        第一个全链接\n",
    "        :param h_pool_flat: 经过一纬度拉伸的数据\n",
    "        :param input_freature: 输入特征数量\n",
    "        :param con_neurons: 神经元数量\n",
    "        :return: 返回计算结果\n",
    "        '''\n",
    "\n",
    "        w_fc = self.init_weight_var(shape=[input_freature, con_neurons])\n",
    "        b_fc = self.init_bias_var([con_neurons])  #偏置数量等于神经元数量\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat, w_fc) + b_fc)\n",
    "        return h_fc1\n",
    "\n",
    "    def build(self):\n",
    "        '''\n",
    "        组建cnn网络\n",
    "        :return:\n",
    "        '''\n",
    "        #定义输入和输入占位符\n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "        self.y = tf.placeholder(dtype='float32', shape=[None, 10])\n",
    "        x_image = tf.reshape(self.x, [-1, 28, 28, 1])  #调整图片尺寸\n",
    "\n",
    "        #第一组卷机池化\n",
    "        h_pool1 = self.creat_conv_pool_layer(input=x_image, input_feature=1, out_feature=self.out_feature1) # input_feature=1是因为输入的是灰度图，通道是1\n",
    "        #第二组卷机池化\n",
    "        h_pool2 = self.creat_conv_pool_layer(input=h_pool1, input_feature=self.out_feature1,\n",
    "                                             out_feature=self.out_feature2)\n",
    "\n",
    "        #全连接\n",
    "        #输入特征数量\n",
    "        h_pool2_flat_features = 7 * 7 * self.out_feature2\n",
    "        #输入特征数据拉平，成了二维，第二个纬度表示有多数样本\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, h_pool2_flat_features])  #-1是自适应样本数量\n",
    "        h_fc1 = self.creat_fc_layer(h_pool_flat=h_pool2_flat,  #数据\n",
    "                                    input_freature=h_pool2_flat_features,  #特征数量\n",
    "                                    con_neurons=self.con_neuroons)  #神经元数量\n",
    "\n",
    "        #丢弃层\n",
    "        self.keep = tf.placeholder('float32')\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob=self.keep)\n",
    "\n",
    "        #输出层\n",
    "        w_fc = self.init_weight_var([self.con_neuroons, 10])\n",
    "        b_fc = self.init_bias_var([10])\n",
    "        pred_y = tf.matmul(h_fc1_drop, w_fc) + b_fc\n",
    "\n",
    "        #计算损失函数交叉熵，这个函数自动计算softmax\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=self.y,  #真实值\n",
    "                                                       logits=pred_y)  #预测值\n",
    "        cross_entropy = tf.reduce_mean(loss)\n",
    "\n",
    "        #准确率\n",
    "        corr_pred = tf.equal(tf.argmax(self.y, axis=1),  #真实类别\n",
    "                             tf.argmax(pred_y, axis=1))  #预测类别\n",
    "        self.acc = tf.reduce_mean(tf.cast(corr_pred, 'float32'))\n",
    "\n",
    "        #优化器,自适应梯度下降优化器\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "    def train(self):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        batch_size = 100\n",
    "        print('开始训练....')\n",
    "\n",
    "        for i in range(10):\n",
    "            total_batch = int(self.data.train.num_examples / batch_size)\n",
    "            for j in range(total_batch):\n",
    "                train_data = self.data.train.next_batch(batch_size=batch_size)\n",
    "                params = {self.x: train_data[0], self.y: train_data[1], self.keep: 0.5}\n",
    "                t, accuracy = self.sess.run([self.train_op, self.acc], feed_dict=params)\n",
    "\n",
    "                if j % 100 == 0:\n",
    "                    print('轮数:{},批次:{},精度:{}'.format(i, j, accuracy))\n",
    "\n",
    "    def metrics(self, x, y, keep):\n",
    "\n",
    "        params = {self.x: x, self.y: y, self.keep: keep}\n",
    "        test_acc = self.sess.run(self.acc, feed_dict=params)\n",
    "        print('测试集精度:', test_acc)\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./fashionmnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./fashionmnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./fashionmnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./fashionmnist/t10k-labels-idx1-ubyte.gz\n",
      "开始训练....\n",
      "轮数:0,批次:0,精度:0.14000000059604645\n",
      "轮数:0,批次:100,精度:0.7200000286102295\n",
      "轮数:0,批次:200,精度:0.8899999856948853\n",
      "轮数:0,批次:300,精度:0.8799999952316284\n",
      "轮数:0,批次:400,精度:0.9300000071525574\n",
      "轮数:0,批次:500,精度:0.9200000166893005\n",
      "轮数:1,批次:0,精度:0.9800000190734863\n",
      "轮数:1,批次:100,精度:0.9200000166893005\n",
      "轮数:1,批次:200,精度:0.9300000071525574\n",
      "轮数:1,批次:300,精度:0.9399999976158142\n",
      "轮数:1,批次:400,精度:0.9599999785423279\n",
      "轮数:1,批次:500,精度:0.9800000190734863\n",
      "轮数:2,批次:0,精度:0.9700000286102295\n",
      "轮数:2,批次:100,精度:0.9399999976158142\n",
      "轮数:2,批次:200,精度:0.9599999785423279\n",
      "轮数:2,批次:300,精度:0.9900000095367432\n",
      "轮数:2,批次:400,精度:0.9800000190734863\n",
      "轮数:2,批次:500,精度:0.9800000190734863\n",
      "轮数:3,批次:0,精度:0.9700000286102295\n",
      "轮数:3,批次:100,精度:0.9900000095367432\n",
      "轮数:3,批次:200,精度:0.9800000190734863\n",
      "轮数:3,批次:300,精度:1.0\n",
      "轮数:3,批次:400,精度:0.9800000190734863\n",
      "轮数:3,批次:500,精度:0.9800000190734863\n",
      "轮数:4,批次:0,精度:0.9900000095367432\n",
      "轮数:4,批次:100,精度:0.9800000190734863\n",
      "轮数:4,批次:200,精度:0.9800000190734863\n",
      "轮数:4,批次:300,精度:0.9700000286102295\n",
      "轮数:4,批次:400,精度:0.9900000095367432\n",
      "轮数:4,批次:500,精度:0.9700000286102295\n",
      "轮数:5,批次:0,精度:0.9800000190734863\n",
      "轮数:5,批次:100,精度:0.9800000190734863\n",
      "轮数:5,批次:200,精度:0.9399999976158142\n",
      "轮数:5,批次:300,精度:0.9599999785423279\n",
      "轮数:5,批次:400,精度:0.9599999785423279\n",
      "轮数:5,批次:500,精度:0.9900000095367432\n",
      "轮数:6,批次:0,精度:0.9700000286102295\n",
      "轮数:6,批次:100,精度:0.9900000095367432\n",
      "轮数:6,批次:200,精度:0.9700000286102295\n",
      "轮数:6,批次:300,精度:0.9700000286102295\n",
      "轮数:6,批次:400,精度:0.9900000095367432\n",
      "轮数:6,批次:500,精度:0.9800000190734863\n",
      "轮数:7,批次:0,精度:0.9700000286102295\n",
      "轮数:7,批次:100,精度:0.9700000286102295\n",
      "轮数:7,批次:200,精度:0.9800000190734863\n",
      "轮数:7,批次:300,精度:0.9800000190734863\n",
      "轮数:7,批次:400,精度:0.9900000095367432\n",
      "轮数:7,批次:500,精度:1.0\n",
      "轮数:8,批次:0,精度:1.0\n",
      "轮数:8,批次:100,精度:0.9800000190734863\n",
      "轮数:8,批次:200,精度:0.9800000190734863\n",
      "轮数:8,批次:300,精度:1.0\n",
      "轮数:8,批次:400,精度:0.9599999785423279\n",
      "轮数:8,批次:500,精度:0.9900000095367432\n",
      "轮数:9,批次:0,精度:0.9800000190734863\n",
      "轮数:9,批次:100,精度:0.9900000095367432\n",
      "轮数:9,批次:200,精度:0.9900000095367432\n",
      "轮数:9,批次:300,精度:0.9800000190734863\n",
      "轮数:9,批次:400,精度:0.9800000190734863\n",
      "轮数:9,批次:500,精度:0.9900000095367432\n",
      "测试集精度:{} 0.98\n"
     ]
    }
   ],
   "source": [
    "fmnist = FashionMnist('./fashionmnist/')  #下载数据\n",
    "fmnist.build()\n",
    "fmnist.train()\n",
    "test_x, test_y = fmnist.data.test.next_batch(100)\n",
    "fmnist.metrics(test_x, test_y, 0.5)\n",
    "fmnist.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}