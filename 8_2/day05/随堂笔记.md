### day01

- 有监督学习：在训练数据中，有输出数据的为有监督学习
- 无监督学习：在训练数据中，没有输出数据的为无监督学习
    - 根据数据的相似程度，划分类别
    - 没有对错，只有好坏
- 回归问题：预测值为连续值
- 分类问题：预测值为离散值
- 聚类问题：聚类属于无监督学习，根据数据的相似程度划分为不同的群落
- fit_transform是两步操作
    - fit()
    - transform()



### day02

- 矩阵相乘：A的所有行 * B的所有列。对应位置相乘再相加

- A的列数  ==  B的行数，才能相乘

- 结果的维度：(A的行数,B的列数)

- 梯度下降：求损失函数的极小值

    - 按照负梯度的方式进行参数更新

    - 负梯度：比极小值小，往大走

        ​                比极小值大，往小走

    - 离极小值越远，下降的越快

    - 离极小值越近，下降的越慢

- 超参数：在构建模型之前，需要设定的参数。决定模型的精度

    - 超参数的取值，大部分取决于经验

- 在训练模型中fit(x,y)

    - x必须是二维数据
    - y最好是一维数据

- 回归问题的损失函数：均方误差



### day03

- 欠拟合：数据分布比较复杂，模型选择的比较简单。模型表达能力不足
- 过拟合：过于拟合训练数据，对训练数据非常好，但测试数据非常差
- 线性模型变种模型的本质：在损失函数后加上正则化，来防止过拟合
    - Lasso回归 ： 损失函数 + L1范数正则化
    - 岭回归: 损失函数 + L2范数正则化
- 在划分数据时，数据一定不能有顺序（随机）
- 单颗决策树，属于弱模型
- Adaboost不断的调整待预测样本数据的权重值



### day04

回归问题简单总结

- 线性回归
- 岭回归，Lasso回归
- 多项式回归
- 决策树回归
    - Adaboost
    - GBDT
    - 随机森林
- 损失函数：均方误差
- 评估指标：
    - 平均绝对误差
    - 中位数绝对偏差
    - r2得分



- 逻辑回归

    - 根据样本数据，构建线性回归模型，得到预测值（连续，线性）
    - 将连续的线性的预测值---》带入逻辑函数sigmoid
    - 将预测值映射到0-1区间内，将线性输出转为非线性
    - 设定阈值0.5,   大于0.5---》1   小于等于0.5--->0

- 查准率：对的个数 / 预测出来的个数

- 召回率：对的个数 / 真实的样本个数

- 查准率和召回率是分开类别单独统计的（每个类别都有自己的查准率和召回率）

- 分类报告:

- ```
    sm.classification_report(test_y,pred_test_y)
    ```

    

- 交叉验证：
    - 一般多用于：模型优化中，针对全部样本进行评估
    - 单独使用：模型构建之后，开始训练之前



- 随着决策树的划分，样本纯度是在不断的提升
- 纯度不断的提升，信息熵在不断的减小
- ID3-》信息增益来作为划分最优分割特征的标准
- C4.5->使用增益率来作为划分最优分割特征的标准



### day05

- 验证曲线：一次只能验证一个模型参数
- 一个好的数据，能够构建好的模型，一个不好的数据，一定不能够构建好的模型
- 分类业务：优先查看类别是否均衡
- 类别均衡：
    - 上采样
    - 下采样
    - 样本不够，权重来凑class_weight='balanced'



- 事件概率： P（A）    P（B）

















